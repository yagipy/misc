{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf2f2e7",
   "metadata": {
    "papermill": {
     "duration": 0.004841,
     "end_time": "2023-05-13T12:09:11.714836",
     "exception": false,
     "start_time": "2023-05-13T12:09:11.709995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is a sample code with Japanese comments.\n",
    "\n",
    "# 3.3 Titanicの先へ行く③！　テキストデータに触れてみよう\n",
    "\n",
    "テーブルデータと共通する部分\n",
    "- 機械学習の教師あり学習\n",
    "    - 学習用データセットの特徴量、目的変数の対応関係を機械学習アルゴリズムで学習して未知のデータセットに対する性能を得る\n",
    "\n",
    "そのままのテキストデータでは機械学習アルゴリズムで扱えない\n",
    "\n",
    "何かしらでベクトルに変換する必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b38f4105",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.016596,
     "end_time": "2023-05-13T12:09:11.735522",
     "exception": false,
     "start_time": "2023-05-13T12:09:11.718926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a0dc8e",
   "metadata": {
    "papermill": {
     "duration": 0.038676,
     "end_time": "2023-05-13T12:09:11.778246",
     "exception": false,
     "start_time": "2023-05-13T12:09:11.739570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like kaggle very much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not like kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do really love machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text\n",
       "0            I like kaggle very much\n",
       "1               I do not like kaggle\n",
       "2  I do really love machine learning"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': ['I like kaggle very much',\n",
    "                            'I do not like kaggle',\n",
    "                            'I do really love machine learning']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17254ba",
   "metadata": {
    "papermill": {
     "duration": 0.003895,
     "end_time": "2023-05-13T12:09:11.786408",
     "exception": false,
     "start_time": "2023-05-13T12:09:11.782513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bag of Words\n",
    "文章で登場した単語の回数を数える方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a620ab1",
   "metadata": {
    "papermill": {
     "duration": 1.017868,
     "end_time": "2023-05-13T12:09:12.808265",
     "exception": false,
     "start_time": "2023-05-13T12:09:11.790397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 配列の1要素が1文に対応\n",
    "# 1文目を抜粋\n",
    "# 元の文章: I like kaggle very much\n",
    "# 変換後の配列: [0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
    "# インデックス: {'i': 1, 'like': 4, 'kaggle': 2, 'very': 10, 'much': 7, 'do': 0, 'not': 8, 'really': 9, 'love': 5, 'machine': 6, 'learning': 3}\n",
    "# 'i', 'kaggle', 'like', 'much', 'very'が文内にそれぞれ1つ存在することが分かる\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "bag = vectorizer.fit_transform(df['text'])\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c88c2a",
   "metadata": {
    "papermill": {
     "duration": 0.011709,
     "end_time": "2023-05-13T12:09:12.824435",
     "exception": false,
     "start_time": "2023-05-13T12:09:12.812726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'like': 4, 'kaggle': 2, 'very': 10, 'much': 7, 'do': 0, 'not': 8, 'really': 9, 'love': 5, 'machine': 6, 'learning': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a980841",
   "metadata": {
    "papermill": {
     "duration": 0.003907,
     "end_time": "2023-05-13T12:09:12.832841",
     "exception": false,
     "start_time": "2023-05-13T12:09:12.828934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TF-IDF\n",
    "単語の珍しさを考慮したベクトル化の手法\n",
    "\n",
    "Term Frequency(単語の登場回数)だけではなく、Inverse Document Frequency(ドキュメント内での登場回数の頻度の逆数)を掛け合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0966b0d",
   "metadata": {
    "papermill": {
     "duration": 0.024308,
     "end_time": "2023-05-13T12:09:12.861350",
     "exception": false,
     "start_time": "2023-05-13T12:09:12.837042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.31544415 0.40619178 0.         0.40619178 0.\n",
      "  0.         0.53409337 0.         0.         0.53409337]\n",
      " [0.43306685 0.33631504 0.43306685 0.         0.43306685 0.\n",
      "  0.         0.         0.56943086 0.         0.        ]\n",
      " [0.34261996 0.26607496 0.         0.45050407 0.         0.45050407\n",
      "  0.45050407 0.         0.         0.45050407 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Bag of Wordsの配列と比較\n",
    "# Bag of Words: [0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
    "# TF-IDF: [0, 0.31544415, 0.40619178, 0, 0.40619178, 0, 0, 0.53409337, 0, 0, 0.53409337]\n",
    "# 0の位置と0より大きい値の位置は同じ\n",
    "# 0か1の離散値ではなく、0~1の連続値を取るようになった\n",
    "# 単語の珍しさに応じて大きな値になっている\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tf = vectorizer.fit_transform(df['text'])\n",
    "tfidf = transformer.fit_transform(tf)\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644ba002",
   "metadata": {
    "papermill": {
     "duration": 0.012722,
     "end_time": "2023-05-13T12:09:12.878348",
     "exception": false,
     "start_time": "2023-05-13T12:09:12.865626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'like': 4, 'kaggle': 2, 'very': 10, 'much': 7, 'do': 0, 'not': 8, 'really': 9, 'love': 5, 'machine': 6, 'learning': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5b6b3",
   "metadata": {
    "papermill": {
     "duration": 0.004035,
     "end_time": "2023-05-13T12:09:12.886883",
     "exception": false,
     "start_time": "2023-05-13T12:09:12.882848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Word2vec\n",
    "\n",
    "単語同士の意味的な近さを考慮したベクトル化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f790932-c132-4f10-b188-90aaff5e3200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from gensim) (1.11.3)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.4 kB)\n",
      "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (26.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.3.3 smart-open-7.1.0 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "288bc8a9",
   "metadata": {
    "papermill": {
     "duration": 0.215184,
     "end_time": "2023-05-13T12:09:13.106398",
     "exception": false,
     "start_time": "2023-05-13T12:09:12.891214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# 学習\n",
    "sentences = [d.split() for d in df['text']]\n",
    "model = word2vec.Word2Vec(sentences, vector_size=10, min_count=1, window=2, seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f34bd29",
   "metadata": {
    "papermill": {
     "duration": 0.014307,
     "end_time": "2023-05-13T12:09:13.125557",
     "exception": false,
     "start_time": "2023-05-13T12:09:13.111250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01650858,  0.01069946,  0.00188946,  0.09910005,  0.06153275,\n",
       "        0.05853238,  0.04005488,  0.02443584, -0.03179482,  0.09779203],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習した単語はベクトル形式に変換できる\n",
    "model.wv['like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa686344",
   "metadata": {
    "papermill": {
     "duration": 0.016794,
     "end_time": "2023-05-13T12:09:13.147293",
     "exception": false,
     "start_time": "2023-05-13T12:09:13.130499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.4254004955291748),\n",
       " ('machine', 0.36355969309806824),\n",
       " ('not', 0.311229407787323),\n",
       " ('kaggle', -0.004140505567193031),\n",
       " ('much', -0.11530754715204239),\n",
       " ('do', -0.1529017835855484),\n",
       " ('love', -0.25542783737182617),\n",
       " ('really', -0.4161785840988159),\n",
       " ('learning', -0.44330498576164246),\n",
       " ('very', -0.4433840215206146)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習に用いた単語の中から似ている単語を抽出できる\n",
    "# 注意: 今回はデータセットが3文しかないので十分に意味の近さを学習できていない\n",
    "model.wv.most_similar('like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b352210",
   "metadata": {
    "papermill": {
     "duration": 0.014548,
     "end_time": "2023-05-13T12:09:13.166721",
     "exception": false,
     "start_time": "2023-05-13T12:09:13.152173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'like', 'kaggle', 'very', 'much']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdf774c3",
   "metadata": {
    "papermill": {
     "duration": 0.015342,
     "end_time": "2023-05-13T12:09:13.186901",
     "exception": false,
     "start_time": "2023-05-13T12:09:13.171559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08898099,  0.02501909,  0.03683598,  0.07944275,  0.01565849,\n",
       "         0.05513714,  0.0667302 , -0.05495857, -0.08889369, -0.03996675],\n",
       "       [ 0.01650858,  0.01069946,  0.00188946,  0.09910005,  0.06153275,\n",
       "         0.05853238,  0.04005488,  0.02443584, -0.03179482,  0.09779203],\n",
       "       [ 0.06329302, -0.03939352, -0.03167932, -0.04431488,  0.04389417,\n",
       "        -0.04902608,  0.09809195, -0.01098474, -0.00437022,  0.00090965],\n",
       "       [ 0.03720424, -0.02774719,  0.02864924,  0.01963681, -0.07835456,\n",
       "        -0.08814968,  0.03203132, -0.02247364,  0.01966591, -0.03539274],\n",
       "       [-0.09157717,  0.04835419, -0.00529734, -0.08170088, -0.05110302,\n",
       "         0.00822875,  0.04535742,  0.00155444,  0.02258943,  0.07426786]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "wordvec = np.array([model.wv[word] for word in df['text'][0].split()])\n",
    "wordvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14f6f82e",
   "metadata": {
    "papermill": {
     "duration": 0.014227,
     "end_time": "2023-05-13T12:09:13.206068",
     "exception": false,
     "start_time": "2023-05-13T12:09:13.191841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02288193,  0.00338641,  0.0060796 ,  0.01443277, -0.00167443,\n",
       "       -0.0030555 ,  0.05645315, -0.01248533, -0.01656068,  0.01952201],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文に登場する単語ベクトルの平均を取る\n",
    "np.mean(wordvec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7c165d1",
   "metadata": {
    "papermill": {
     "duration": 0.014178,
     "end_time": "2023-05-13T12:09:13.225310",
     "exception": false,
     "start_time": "2023-05-13T12:09:13.211132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08898099, 0.04835419, 0.03683598, 0.09910005, 0.06153275,\n",
       "       0.05853238, 0.09809195, 0.02443584, 0.02258943, 0.09779203],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文に登場する単語ベクトルの各要素の最大値を取る\n",
    "# SWEM-maxと呼ばれる\n",
    "np.max(wordvec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dbd6bea",
   "metadata": {
    "papermill": {
     "duration": 0.004525,
     "end_time": "2023-05-13T12:09:13.234876",
     "exception": false,
     "start_time": "2023-05-13T12:09:13.230351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 各単語の時系列データとして扱う手法もある(ここでは紹介のみ)\n",
    "# 文中の単語の順番に関する情報を考慮できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f4038c8-5dcf-4684-afc2-ce25c3780baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('財政', 0.7547577023506165),\n",
       " ('政策', 0.723992109298706),\n",
       " ('産業', 0.7084316611289978),\n",
       " ('社会', 0.6861709952354431),\n",
       " ('対外', 0.6856389045715332),\n",
       " ('資本', 0.6762275695800781),\n",
       " ('政治', 0.6757708191871643),\n",
       " ('格差', 0.6638521552085876),\n",
       " ('農業', 0.6553444862365723),\n",
       " ('軍事', 0.6500835418701172)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# 日本語版Wikipediaで学習したWord2vec\n",
    "# https://hironsan.hatenablog.com/entry/japanese-text8-corpus\n",
    "sentences = word2vec.Text8Corpus(\"../input/ja.text8\")\n",
    "model = word2vec.Word2Vec(sentences)\n",
    "model.wv.most_similar([\"経済\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.148552,
   "end_time": "2023-05-13T12:09:14.160444",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-13T12:09:03.011892",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
